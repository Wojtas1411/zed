---
title: "Report"
author: "Me"
date: "Today"
knit: (function(input_file, encoding) {
  out_dir <- 'html';
  rmarkdown::render(input_file, encoding=encoding, output_file=file.path(dirname(input_file), out_dir, 'index.html'))
 })


output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE}
library(openxlsx)
library(httr)
library(arules)
```
# Data preprocessing
## Read Data
```{r read-data}
# https://stackoverflow.com/a/41368947
url <- "http://www.cs.put.poznan.pl/dbrzezinski/teaching/zed/wuhan_blood_sample_data_Jan_Feb_2020.xlsx"
GET(url, write_disk(tf <- tempfile(fileext = ".xlsx")))
df <- read.xlsx(tf, fillMergedCells = TRUE)
```

## Preprocess
TODO

## Print summary
```{r summary}
sapply(df, summary)
```

## "Transakcje" badań
Zauważamy, że dużo NA, wynika to z tego, że badania są rozrzucone.
Badanie zbiorów, czy któreś są częstsze niż inne.
```{r transactions}
# tr.tf - transactions - TRUE/FALSE
tr.tf <- sapply(df[,-(1:7)], function(x) !is.na(x))
transactions <- apply(tr.tf, 1, function(x) colnames(tr.tf)[x])
# tr.str <- sapply(transactions, function(x) paste(x, collapse=", "))
```

Ilość unikalnych transakcji
```{r unique-transactions}
uni.sets <- unique(transactions)
length(uni.sets)
```

Szukamy maksymalnych domkniętych zbiorów częstych - sprawdzamy czy badania występują w grupach.

```{r apriori}
itemsets <- apriori(tr.tf, parameter = list(target="closed frequent itemsets", support=.05, minlen=1, maxlen=30, maxtime=60))
mc_itemsets <- itemsets[is.maximal(itemsets)]
mc_itemsets
```

```{r inspect itemsets}
inspect(head(sort(mc_itemsets, by = 'support'), 10))
```

Kolejny krok - agregacja transakcji według okna. 

## Grupowanie
Z braku sensownego pomysłu wykonania, porzucamy ideę agregacji według okna, samo grupowanie według patient id musi wystarczyć.
```{r}
```